{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "#import tqdm\n",
    "import numpy as np\n",
    "#import pandas as pd\n",
    "import multiprocessing\n",
    "import pydicom as dicom\n",
    "import nibabel as nib\n",
    "#from keras import utils as kutils\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def load_image(label_fpath, transpose=False):\n",
    "    #encode_name = label_fpath[-39: -7]\n",
    "    label_data = nib.load(label_fpath)\n",
    "    label_array = label_data.get_fdata()\n",
    "    if transpose:\n",
    "        label_array = np.transpose(label_array, axes=(2, 1, 0))\n",
    "    return  label_array#, encode_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/u/wartytw\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "info = pd.read_csv('/data2/pancreas/Nifti_data/data_list.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"/data2/pancreas/Nifti_data/image\"\n",
    "label_path = \"/data2/pancreas/Nifti_data/label\"\n",
    "\n",
    "resec_train = np.load(\"resec_train.npy\")\n",
    "resec_val = np.load(\"resec_val.npy\")\n",
    "y_train = np.load(\"y_train.npy\")\n",
    "y_val = np.load(\"y_val.npy\")\n",
    "\n",
    "resec = np.concatenate([resec_train,resec_val], axis = 0)\n",
    "y = np.concatenate([y_train, y_val], axis = 0)\n",
    "\n",
    "box_tumor = np.load(\"box_tumor.npy\")\n",
    "box_pancreas = np.load(\"box_pancreas.npy\")\n",
    "\n",
    "import pandas as pd\n",
    "info = pd.read_csv('/data2/pancreas/Nifti_data/data_list.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "from scipy import ndimage\n",
    "\n",
    "\n",
    "#from label(whole pancreas) to tumor_only masking\n",
    "def extract_tumor(tmp_slide):\n",
    "    t_tmp_slide = np.zeros((tmp_slide.shape[0], tmp_slide.shape[1]))\n",
    "    for i in range(tmp_slide.shape[0]):\n",
    "        for j in range(tmp_slide.shape[1]):\n",
    "            if(tmp_slide[i, j] == 2):\n",
    "                t_tmp_slide[i, j] = 2\n",
    "    return t_tmp_slide\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#masking for pancreas-tumor\n",
    "def masking_dilation_erosion(tmp_slide, t_tmp_slide):\n",
    "    tt_tmp_slide = np.zeros((tmp_slide.shape[0], tmp_slide.shape[1]))\n",
    "    for i in range(tmp_slide.shape[0]):\n",
    "        for j in range(tmp_slide.shape[1]):\n",
    "            if(tmp_slide[i, j] != 0 and t_tmp_slide[i, j] != 1):\n",
    "                tt_tmp_slide[i, j] = 1\n",
    "    return tt_tmp_slide\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masking_image(label, img):\n",
    "    ll = np.zeros((label.shape[0], label.shape[1]))\n",
    "    for i in range(label.shape[0]):\n",
    "        for j in range(label.shape[1]):\n",
    "            if(label[i, j] == 1):\n",
    "                ll[i, j] = img[i, j]\n",
    "    return ll\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_image(img):\n",
    "    top = max(np.where(img != 0)[0])\n",
    "    down = min(np.where(img != 0)[0])\n",
    "    r = max(np.where(img != 0)[1])\n",
    "    l = min(np.where(img != 0)[1])\n",
    "    return img[down:top+1, l:r+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#each input slide is 100*100 vector, and a input include 3 slides(for CBD, SMV, Retro respectively)\n",
    "\n",
    "import cv2\n",
    "import math\n",
    "\n",
    "#定义最大灰度级数\n",
    "gray_level = 3001\n",
    "\n",
    "def maxGrayLevel(img):\n",
    "    max_gray_level=0\n",
    "    (height,width)=img.shape\n",
    "    for y in range(height):\n",
    "        for x in range(width):\n",
    "            if img[y][x] > max_gray_level:\n",
    "                max_gray_level = img[y][x]\n",
    "    return max_gray_level+1\n",
    "\n",
    "def getGlcm(input,d_x,d_y):\n",
    "    srcdata=input.copy()\n",
    "    max_value = np.max(srcdata)\n",
    "    min_value = np.min(srcdata)\n",
    "    for i in range(srcdata.shape[0]):\n",
    "        for j in range(srcdata.shape[1]):\n",
    "            srcdata[i, j] = int((srcdata[i, j] - min_value)/(max_value - min_value)*(gray_level - 1))\n",
    "#     print(srcdata)\n",
    "    ret=[[0.0 for i in range(gray_level)] for j in range(gray_level)]\n",
    "    (height,width) = input.shape\n",
    "    \n",
    "    max_gray_level=maxGrayLevel(input)\n",
    "    \n",
    "    #若灰度级数大于gray_level，则将图像的灰度级缩小至gray_level，减小灰度共生矩阵的大小\n",
    "    \n",
    "#     if max_gray_level > gray_level:\n",
    "#         for j in range(height):\n",
    "#             for i in range(width):\n",
    "#                 srcdata[j][i] = srcdata[j][i]*gray_level / max_gray_level\n",
    "\n",
    "    for j in range(height-abs(d_y)):\n",
    "        for i in range(width-abs(d_x)):\n",
    "            rows = int(srcdata[j][i])\n",
    "            cols = int(srcdata[j + d_y][i+d_x])\n",
    "            ret[rows][cols]+=1.0\n",
    "\n",
    "#     for i in range(gray_level):\n",
    "#         for j in range(gray_level):\n",
    "#             ret[i][j]/=float(height*width)\n",
    "\n",
    "    return np.array(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PT7\n",
      "PC607\n",
      "PC602\n",
      "PC600\n",
      "PC593\n",
      "PC573\n",
      "PC570\n",
      "PC561\n",
      "PC536\n",
      "PC595\n",
      "PC580\n",
      "PC556\n",
      "PC540\n",
      "PC768\n",
      "PC42\n",
      "PC104\n",
      "PC285\n",
      "PC636\n",
      "PC535\n",
      "PC563\n",
      "PC519\n",
      "PC447\n",
      "PC484\n",
      "PC898\n",
      "PC818\n",
      "PC699\n",
      "PC769\n",
      "PC739\n",
      "PT12\n",
      "PC581\n",
      "PC544\n",
      "PC537\n",
      "PT8\n",
      "PC116\n",
      "PC545\n",
      "PC583\n",
      "PC456\n",
      "PC477\n",
      "created new_y\n"
     ]
    }
   ],
   "source": [
    "new_y = []\n",
    "\n",
    "# Establish The npz data (3 glcm slide for each input)\n",
    "from keras.utils import to_categorical\n",
    "from scipy import ndimage\n",
    "type_name_pd = pd.DataFrame(info.groupby(['resection', 'SMV', 'CBD',  'retroperitoneal']).case_id)\n",
    "\n",
    "#create [name, index, y], notice that y = vector(5)\n",
    "kk = 0\n",
    "num_type = len(type_name_pd) - 1\n",
    "for i in range(num_type):    #neglect x, x, x\n",
    "    vec5 = [0 for i in range(num_type)]\n",
    "    vec5[i] = 1\n",
    "    n = len(type_name_pd[1][i])\n",
    "    total_val = 0\n",
    "    for j in range(n):\n",
    "        name = type_name_pd[1][i].iloc[j]\n",
    "        \n",
    "        name_idx = np.where(resec == name)[0][0]\n",
    "        image = load_image(os.path.join(image_path, \"IM_\"+name+\".nii.gz\"))\n",
    "        label = load_image(os.path.join(label_path, \"LB_\"+name+\".nii.gz\"))\n",
    "        print(name)\n",
    "        for k in range(int(box_tumor[name_idx, 4]), int(box_tumor[name_idx, 5])+1):\n",
    "            \n",
    "            tmp_slide = label[..., k]\n",
    "            tmp_slide_img = image[..., k]\n",
    "            if(np.where(tmp_slide == 2)[0].size == 0):\n",
    "                continue\n",
    "            \n",
    "            \n",
    "            new_y.append(vec5)\n",
    "            kk+=1\n",
    "            \n",
    "            \n",
    "        \n",
    "        del image, label\n",
    "print(\"created new_y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create io_arr\n"
     ]
    }
   ],
   "source": [
    "type_name_pd = pd.DataFrame(info.groupby(['resection', 'SMV', 'CBD',  'retroperitoneal']).case_id)\n",
    "\n",
    "#create [name, index, y], notice that y = vector(5)\n",
    "io_arr = [[] for i in range(3)]\n",
    "num_type = len(type_name_pd) - 1\n",
    "for i in range(num_type):    #neglect x, x, x\n",
    "    vec5 = [0 for i in range(num_type)]\n",
    "    vec5[i] = 1\n",
    "    n = len(type_name_pd[1][i])\n",
    "    total_val = 0\n",
    "    for j in range(n):\n",
    "        name = type_name_pd[1][i].iloc[j]\n",
    "        name_idx = np.where(resec == name)[0][0]\n",
    "\n",
    "        image = load_image(os.path.join(image_path, \"IM_\"+name+\".nii.gz\"))\n",
    "        label = load_image(os.path.join(label_path, \"LB_\"+name+\".nii.gz\"))\n",
    "\n",
    "        for k in range(int(box_tumor[name_idx, 4]), int(box_tumor[name_idx, 5])+1):\n",
    "            \n",
    "            tmp_slide = label[..., k]\n",
    "            tmp_slide_img = image[..., k]\n",
    "            if(np.where(tmp_slide == 2)[0].size == 0):\n",
    "                continue\n",
    "            io_arr[0].append(name)\n",
    "            io_arr[1].append(k)\n",
    "            io_arr[2].append(vec5)\n",
    "        del image, label\n",
    "print(\"create io_arr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   1.,   2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.,  10.,\n",
       "        11.,  12.,  13.,  14.,  15.,  16.,  17.,  18.,  19.,  20.,  21.,\n",
       "        22.,  23.,  24.,  25.,  26.,  27.,  28.,  29.,  30.,  31.,  32.,\n",
       "        33.,  34.,  35.,  36.,  37.,  38.,  39.,  40.,  41.,  42.,  43.,\n",
       "        44.,  45.,  46.,  47.,  48.,  49.,  50.,  51.,  52.,  53.,  54.,\n",
       "        55.,  56.,  57.,  58.,  59.,  60.,  61.,  62.,  63.,  64.,  65.,\n",
       "        66.,  67.,  68.,  69.,  70.,  71.,  72.,  73.,  74.,  75.,  76.,\n",
       "        77.,  78.,  79.,  80.,  81.,  82.,  83.,  84.,  85.,  86.,  87.,\n",
       "        88.,  89.,  90.,  91.,  92.,  93.,  94.,  95.,  96.,  97.,  98.,\n",
       "        99., 100., 101., 102., 103., 104., 105., 106., 107., 108., 109.,\n",
       "       110., 111., 112., 113., 114., 115., 116., 117., 118., 119., 120.,\n",
       "       121., 122., 123., 124., 125., 126., 127., 128., 129., 130., 131.,\n",
       "       132., 133., 134., 135., 136., 137., 138., 139., 140., 141., 142.,\n",
       "       143., 144., 145., 146., 147., 148., 149., 150., 151., 152., 153.,\n",
       "       154., 155., 156., 157., 158., 159., 160., 161., 162., 163., 164.,\n",
       "       165., 166., 167., 168., 169., 170., 171., 172., 173., 174., 175.,\n",
       "       176., 177., 178.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order_arr = np.zeros((len(io_arr[0]), 1))\n",
    "for i in range(order_arr.shape[0]):\n",
    "    order_arr[i] = i\n",
    "import random\n",
    "\n",
    "\n",
    "#random.shuffle(order_arr)\n",
    "np.random.shuffle(order_arr)\n",
    "np.unique(order_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model#, load_model\n",
    "from keras import layers as klayers\n",
    "from keras.optimizers import Adam\n",
    "from keras import utils as kutils\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from keras.layers import Conv3D, MaxPool3D, Flatten, Dense\n",
    "from keras.layers import Dropout, Input, BatchNormalization\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "#from plotly.offline import iplot, init_notebook_mode\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adadelta\n",
    "#import plotly.graph_objs as go\n",
    "from matplotlib.pyplot import cm\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "import keras\n",
    "import h5py\n",
    "\n",
    "#init_notebook_mode(connected=True)\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, multiply, concatenate,  MaxPool2D, Reshape\n",
    "# from keras.layers import BatchNormalization, Activation, Embedding, ZeroPadding2D, Lambda\n",
    "from keras.layers.advanced_activations import LeakyReLU, ReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D, Conv1D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.utils import to_categorical\n",
    "import keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, LSTM, TimeDistributed, RepeatVector, Reshape\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "map_df = pd.DataFrame(data={'resec_name': io_arr[0], 'idx': io_arr[1], 'target':io_arr[2], 'order' : order_arr.reshape(len(io_arr[0]))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "from scipy import ndimage\n",
    "class resec_Generator1(kutils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, mapping_df, batch_size, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.mapping_df = mapping_df\n",
    "        self.data_num   = mapping_df.shape[0]\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(self.data_num / self.batch_size))\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        #print(\"enter0\")\n",
    "        batch_mapping_df = \\\n",
    "            self.mapping_df.iloc[index*self.batch_size: (index+1)*self.batch_size]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(batch_mapping_df)\n",
    "        return X, y\n",
    "\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        if self.shuffle:\n",
    "            self.mapping_df = self.mapping_df.sample(frac=1).reset_index(drop=True)\n",
    "            \n",
    "    def __data_generation(self, batch_mapping_df):\n",
    "        'Generates data containing batch_size samples' \n",
    "        # Initialization\n",
    "        X = np.zeros((  self.batch_size, 3000, 3000, 3, 1)) \n",
    "\n",
    "\n",
    "        y = np.zeros((self.batch_size, 5))\n",
    "\n",
    "        # Generate data\n",
    "        cnt = 0\n",
    "        \n",
    "        for i, row in batch_mapping_df.iterrows():\n",
    "            #img = extract_cube(shape_tumor[row['shape']], load_image(os.path.join(image_path, \"IM_\"+row['resec_name']+\".nii.gz\")))\n",
    "            idx = int(row['order'])#encode = row['resec_name']\n",
    "            encode = io_arr[0][idx]\n",
    "            image = load_image(os.path.join(image_path, \"IM_\"+encode+\".nii.gz\"))\n",
    "            label = load_image(os.path.join(label_path, \"LB_\"+encode+\".nii.gz\"))\n",
    "            k = io_arr[1][idx]\n",
    "            tmp_slide = label[..., k]\n",
    "            tmp_slide_img = image[..., k]\n",
    "            if(np.where(tmp_slide == 2)[0].size == 0):\n",
    "                continue\n",
    "            down = max(np.where(tmp_slide == 2)[0])\n",
    "            top = min(np.where(tmp_slide == 2)[0])\n",
    "            r = max(np.where(tmp_slide == 2)[1])\n",
    "            l = min(np.where(tmp_slide == 2)[1])\n",
    "            center = int((down + top)/2), int((r + l)/2)\n",
    "            dilation_pancreas = ndimage.binary_dilation(tmp_slide, iterations = 10).astype(tmp_slide.dtype)\n",
    "            erosion_tumor = ndimage.binary_erosion(extract_tumor(tmp_slide), iterations = 1).astype(tmp_slide.dtype)\n",
    "            final_masking_label = masking_dilation_erosion(dilation_pancreas, erosion_tumor)\n",
    "            CBD = final_masking_label[:center[0], :center[1]]\n",
    "            CBD_tmp_slide_img = tmp_slide_img[:center[0], :center[1]]\n",
    "\n",
    "            SMV = final_masking_label[:center[0], center[1]:]\n",
    "            SMV_tmp_slide_img = tmp_slide_img[:center[0], center[1]:]\n",
    "\n",
    "            Retro = final_masking_label[center[0]:, :]\n",
    "            Retro_tmp_slide_img = tmp_slide_img[center[0]:, :]\n",
    "\n",
    "            \n",
    "            CBD_image = masking_image(CBD, CBD_tmp_slide_img)\n",
    "            SMV_image = masking_image(SMV, SMV_tmp_slide_img)\n",
    "            Retro_image = masking_image(Retro, Retro_tmp_slide_img)\n",
    "            \n",
    "            CBD_image = clip_image(CBD_image)\n",
    "            SMV_image = clip_image(SMV_image)\n",
    "            Retro_image = clip_image(Retro_image)\n",
    "\n",
    "            CBD_image = getGlcm(CBD_image,-1,1)\n",
    "            SMV_image = getGlcm(SMV_image,1,1)\n",
    "            Retro_image = getGlcm(Retro_image,0,-1)\n",
    "            \n",
    "            glcm_input = np.concatenate([np.expand_dims(getGlcm(CBD_image,-1,1), axis = 2), np.expand_dims(getGlcm(SMV_image,1,1), axis = 2), np.expand_dims(getGlcm(Retro_image,0,-1), axis = 2)], axis = 2)\n",
    "\n",
    "            #print(encode)\n",
    "            X[ cnt, :, :, :, 0] = glcm_input[:3000, :3000, :]\n",
    "            del image, label\n",
    "            y[cnt, :] = io_arr[2][idx]\n",
    "\n",
    "\n",
    "            cnt += 1\n",
    "        #print(X[5])\n",
    "        return X, y\n",
    "\n",
    "# for name in resec:\n",
    "#     img = load_image(os.path.join(image_path, \"IM_\"+name+\".nii.gz\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3000, 3000, 3, 1)  0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 300, 300, 300, 1)  0         \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 298, 298, 298, 16) 448       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 149, 149, 149, 16) 0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 74, 74, 74, 16)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 74, 74, 74, 16)    64        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 74, 74, 74, 16)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 37, 37, 37, 16)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 35, 35, 35, 8)     3464      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 35, 35, 35, 8)     32        \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 35, 35, 35, 8)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_4 (MaxPooling3 (None, 17, 17, 17, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 15, 15, 15, 8)     1736      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 15, 15, 15, 8)     32        \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 15, 15, 15, 8)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_5 (MaxPooling3 (None, 7, 7, 7, 8)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2744)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               274500    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 5)                 55        \n",
      "=================================================================\n",
      "Total params: 285,891\n",
      "Trainable params: 285,827\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import metrics\n",
    "tmp_x = Input(( 3000, 3000, 3, 1))\n",
    "\n",
    "x = Reshape(( 300, 300, 300, 1))(tmp_x)\n",
    "x = Conv3D(filters=16, dilation_rate=1, kernel_size=(3, 3, 3), activation='relu',kernel_initializer = keras.initializers.he_normal(seed=None))(x)\n",
    "x = MaxPool3D()(x)\n",
    "x = MaxPool3D()(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = MaxPool3D()(x)\n",
    "\n",
    "\n",
    "\n",
    "x = Conv3D(filters=8, dilation_rate=1, kernel_size=(3, 3, 3), activation='relu',kernel_initializer = keras.initializers.he_normal(seed=None))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = MaxPool3D()(x)\n",
    "\n",
    "x = Conv3D(filters=8, dilation_rate=1, kernel_size=(3, 3, 3), activation='relu',kernel_initializer = keras.initializers.he_normal(seed=None))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = MaxPool3D()(x)\n",
    "\n",
    "# x = Conv3D(filters=4, dilation_rate=1, kernel_size=(3, 3, 3), activation='relu',kernel_initializer = keras.initializers.he_normal(seed=None))(tmp_x)\n",
    "# x = BatchNormalization()(x)\n",
    "# x = Dropout(0.5)(x)\n",
    "\n",
    "# x = Conv3D(filters=2, dilation_rate=1, kernel_size=(3, 3, 3), activation='relu',kernel_initializer = keras.initializers.he_normal(seed=None))(tmp_x)\n",
    "# x = BatchNormalization()(x)\n",
    "# x = Dropout(0.5)(x)\n",
    "\n",
    "\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Dense(units=100, kernel_initializer = keras.initializers.he_normal(seed=None), activation='elu')(x)\n",
    "x = Dense(units=50, activation='selu')(x)\n",
    "x = Dense(units=10, activation='relu')(x)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x = Dense(5, activation='sigmoid')(x)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = Model(inputs=tmp_x, outputs=x)\n",
    "adam_lr = 0.0003\n",
    "adam_beta_1 = 0.5\n",
    "model.compile(optimizer=Adam(lr=adam_lr, beta_1=adam_beta_1),\n",
    "              loss='categorical_crossentropy', metrics = [metrics.categorical_accuracy])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "v_generator = resec_Generator1(map_df[:-20], batch_size=batch_size)\n",
    "validation_generator = resec_Generator1(map_df[-20:], batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "159/159 [==============================] - 12390s 78s/step - loss: 1.8269 - categorical_accuracy: 0.2704 - val_loss: 1.5584 - val_categorical_accuracy: 0.1500\n",
      "Epoch 2/100\n",
      "159/159 [==============================] - 11420s 72s/step - loss: 1.5772 - categorical_accuracy: 0.2642 - val_loss: 1.5702 - val_categorical_accuracy: 0.2000\n",
      "Epoch 3/100\n",
      "159/159 [==============================] - 11611s 73s/step - loss: 1.5039 - categorical_accuracy: 0.3522 - val_loss: 1.5945 - val_categorical_accuracy: 0.1000\n",
      "Epoch 4/100\n",
      "159/159 [==============================] - 11469s 72s/step - loss: 1.4695 - categorical_accuracy: 0.4025 - val_loss: 1.5827 - val_categorical_accuracy: 0.0500\n",
      "Epoch 5/100\n",
      "159/159 [==============================] - 11590s 73s/step - loss: 1.5431 - categorical_accuracy: 0.3899 - val_loss: 1.5884 - val_categorical_accuracy: 0.1000\n",
      "Epoch 6/100\n",
      "159/159 [==============================] - 11284s 71s/step - loss: 1.4492 - categorical_accuracy: 0.3836 - val_loss: 1.5820 - val_categorical_accuracy: 0.1000\n",
      "Epoch 7/100\n",
      "159/159 [==============================] - 11491s 72s/step - loss: 1.4309 - categorical_accuracy: 0.3396 - val_loss: 1.5845 - val_categorical_accuracy: 0.1000\n",
      "Epoch 8/100\n",
      "159/159 [==============================] - 11477s 72s/step - loss: 1.4772 - categorical_accuracy: 0.3774 - val_loss: 1.5858 - val_categorical_accuracy: 0.2000\n",
      "Epoch 9/100\n",
      "159/159 [==============================] - 11760s 74s/step - loss: 1.3733 - categorical_accuracy: 0.4025 - val_loss: 1.5896 - val_categorical_accuracy: 0.2500\n",
      "Epoch 10/100\n",
      "159/159 [==============================] - 11392s 72s/step - loss: 1.4626 - categorical_accuracy: 0.3774 - val_loss: 1.5969 - val_categorical_accuracy: 0.2000\n",
      "Epoch 11/100\n",
      "159/159 [==============================] - 11611s 73s/step - loss: 1.3756 - categorical_accuracy: 0.4591 - val_loss: 1.5941 - val_categorical_accuracy: 0.2500\n",
      "Epoch 12/100\n",
      "159/159 [==============================] - 11286s 71s/step - loss: 1.3964 - categorical_accuracy: 0.4151 - val_loss: 1.5769 - val_categorical_accuracy: 0.2500\n",
      "Epoch 13/100\n",
      "159/159 [==============================] - 11591s 73s/step - loss: 1.4212 - categorical_accuracy: 0.4528 - val_loss: 1.5767 - val_categorical_accuracy: 0.2500\n",
      "Epoch 14/100\n",
      "159/159 [==============================] - 11370s 72s/step - loss: 1.4320 - categorical_accuracy: 0.4151 - val_loss: 1.5723 - val_categorical_accuracy: 0.2000\n",
      "Epoch 15/100\n",
      "159/159 [==============================] - 11489s 72s/step - loss: 1.3635 - categorical_accuracy: 0.4151 - val_loss: 1.5693 - val_categorical_accuracy: 0.3000\n",
      "Epoch 16/100\n",
      "159/159 [==============================] - 11315s 71s/step - loss: 1.3867 - categorical_accuracy: 0.3774 - val_loss: 1.5736 - val_categorical_accuracy: 0.3000\n",
      "Epoch 17/100\n",
      "159/159 [==============================] - 11458s 72s/step - loss: 1.3830 - categorical_accuracy: 0.3962 - val_loss: 1.5500 - val_categorical_accuracy: 0.2500\n",
      "Epoch 18/100\n",
      "159/159 [==============================] - 11592s 73s/step - loss: 1.3429 - categorical_accuracy: 0.4088 - val_loss: 1.5516 - val_categorical_accuracy: 0.3000\n",
      "Epoch 19/100\n",
      "159/159 [==============================] - 11464s 72s/step - loss: 1.3524 - categorical_accuracy: 0.3899 - val_loss: 1.5639 - val_categorical_accuracy: 0.1500\n",
      "Epoch 20/100\n",
      "159/159 [==============================] - 11283s 71s/step - loss: 1.3954 - categorical_accuracy: 0.3711 - val_loss: 1.5843 - val_categorical_accuracy: 0.3000\n",
      "Epoch 21/100\n",
      "159/159 [==============================] - 11733s 74s/step - loss: 1.4395 - categorical_accuracy: 0.3774 - val_loss: 1.5894 - val_categorical_accuracy: 0.2000\n",
      "Epoch 22/100\n",
      "130/159 [=======================>......] - ETA: 31:04 - loss: 1.3512 - categorical_accuracy: 0.4308"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159/159 [==============================] - 11676s 73s/step - loss: 1.2855 - categorical_accuracy: 0.4340 - val_loss: 1.4886 - val_categorical_accuracy: 0.2500\n",
      "Epoch 53/100\n",
      "159/159 [==============================] - 11474s 72s/step - loss: 1.3146 - categorical_accuracy: 0.4403 - val_loss: 1.4740 - val_categorical_accuracy: 0.4000\n",
      "Epoch 54/100\n",
      "159/159 [==============================] - 11512s 72s/step - loss: 1.3069 - categorical_accuracy: 0.4151 - val_loss: 1.5249 - val_categorical_accuracy: 0.2500\n",
      "Epoch 55/100\n",
      "159/159 [==============================] - 11512s 72s/step - loss: 1.2791 - categorical_accuracy: 0.4717 - val_loss: 1.5314 - val_categorical_accuracy: 0.2500\n",
      "Epoch 56/100\n",
      "159/159 [==============================] - 11353s 71s/step - loss: 1.3130 - categorical_accuracy: 0.4528 - val_loss: 1.5398 - val_categorical_accuracy: 0.2500\n",
      "Epoch 57/100\n",
      "159/159 [==============================] - 11511s 72s/step - loss: 1.3454 - categorical_accuracy: 0.4214 - val_loss: 1.5176 - val_categorical_accuracy: 0.2000\n",
      "Epoch 58/100\n",
      "159/159 [==============================] - 11445s 72s/step - loss: 1.2617 - categorical_accuracy: 0.4465 - val_loss: 1.5246 - val_categorical_accuracy: 0.3000\n",
      "Epoch 59/100\n",
      "159/159 [==============================] - 11543s 73s/step - loss: 1.2998 - categorical_accuracy: 0.4403 - val_loss: 1.5267 - val_categorical_accuracy: 0.3500\n",
      "Epoch 60/100\n",
      "159/159 [==============================] - 11491s 72s/step - loss: 1.2477 - categorical_accuracy: 0.4717 - val_loss: 1.5242 - val_categorical_accuracy: 0.3500\n",
      "Epoch 61/100\n",
      "159/159 [==============================] - 11234s 71s/step - loss: 1.2884 - categorical_accuracy: 0.4277 - val_loss: 1.5063 - val_categorical_accuracy: 0.3000\n",
      "Epoch 62/100\n",
      "159/159 [==============================] - 11684s 73s/step - loss: 1.3016 - categorical_accuracy: 0.5157 - val_loss: 1.5306 - val_categorical_accuracy: 0.3000\n",
      "Epoch 63/100\n",
      "159/159 [==============================] - 11401s 72s/step - loss: 1.2247 - categorical_accuracy: 0.4780 - val_loss: 1.5037 - val_categorical_accuracy: 0.3000\n",
      "Epoch 64/100\n",
      "159/159 [==============================] - 11344s 71s/step - loss: 1.2908 - categorical_accuracy: 0.4214 - val_loss: 1.5144 - val_categorical_accuracy: 0.3500\n",
      "Epoch 65/100\n",
      "159/159 [==============================] - 11464s 72s/step - loss: 1.2591 - categorical_accuracy: 0.4780 - val_loss: 1.5100 - val_categorical_accuracy: 0.2500\n",
      "Epoch 66/100\n",
      "159/159 [==============================] - 11615s 73s/step - loss: 1.3553 - categorical_accuracy: 0.3962 - val_loss: 1.4965 - val_categorical_accuracy: 0.3500\n",
      "Epoch 67/100\n",
      "159/159 [==============================] - 11493s 72s/step - loss: 1.2523 - categorical_accuracy: 0.4214 - val_loss: 1.4541 - val_categorical_accuracy: 0.3500\n",
      "Epoch 68/100\n",
      "159/159 [==============================] - 11230s 71s/step - loss: 1.3003 - categorical_accuracy: 0.4654 - val_loss: 1.4698 - val_categorical_accuracy: 0.2500\n",
      "Epoch 69/100\n",
      "159/159 [==============================] - 11430s 72s/step - loss: 1.3338 - categorical_accuracy: 0.4151 - val_loss: 1.4730 - val_categorical_accuracy: 0.3000\n",
      "Epoch 70/100\n",
      "131/159 [=======================>......] - ETA: 30:29 - loss: 1.2215 - categorical_accuracy: 0.4427"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-3be13bdfe368>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m history = model.fit_generator(v_generator,\n\u001b[0;32m----> 2\u001b[0;31m                               epochs=100, validation_data=validation_generator)\n\u001b[0m",
      "\u001b[0;32m/opt/python-3.6-packages/keras/2.2.4/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/python-3.6-packages/keras/2.2.4/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/python-3.6-packages/keras/2.2.4/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    232\u001b[0m                             \u001b[0mval_enqueuer_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m                             \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                             workers=0)\n\u001b[0m\u001b[1;32m    235\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                         \u001b[0;31m# No need for try/except because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/python-3.6-packages/keras/2.2.4/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/python-3.6-packages/keras/2.2.4/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate_generator\u001b[0;34m(self, generator, steps, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[1;32m   1470\u001b[0m             \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1471\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m             verbose=verbose)\n\u001b[0m\u001b[1;32m   1473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/python-3.6-packages/keras/2.2.4/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mevaluate_generator\u001b[0;34m(model, generator, steps, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m             \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m                 raise ValueError('Output of generator should be a tuple '\n",
      "\u001b[0;32m/opt/python-3.6-packages/keras/2.2.4/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    596\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/5.2.0/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/5.2.0/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/5.2.0/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/5.2.0/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(v_generator,\n",
    "                              epochs=100, validation_data=validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "159/159 [==============================] - 12123s 76s/step - loss: 1.2567 - categorical_accuracy: 0.4591 - val_loss: 1.5015 - val_categorical_accuracy: 0.3000\n",
      "Epoch 2/30\n",
      "159/159 [==============================] - 11503s 72s/step - loss: 1.2203 - categorical_accuracy: 0.4843 - val_loss: 1.4879 - val_categorical_accuracy: 0.3000\n",
      "Epoch 3/30\n",
      "159/159 [==============================] - 11388s 72s/step - loss: 1.2377 - categorical_accuracy: 0.4591 - val_loss: 1.4927 - val_categorical_accuracy: 0.3000\n",
      "Epoch 4/30\n",
      "159/159 [==============================] - 11372s 72s/step - loss: 1.1909 - categorical_accuracy: 0.5157 - val_loss: 1.4913 - val_categorical_accuracy: 0.3500\n",
      "Epoch 5/30\n",
      "159/159 [==============================] - 11520s 72s/step - loss: 1.2556 - categorical_accuracy: 0.4528 - val_loss: 1.5176 - val_categorical_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "159/159 [==============================] - 11564s 73s/step - loss: 1.3339 - categorical_accuracy: 0.4591 - val_loss: 1.5212 - val_categorical_accuracy: 0.2000\n",
      "Epoch 7/30\n",
      "159/159 [==============================] - 11540s 73s/step - loss: 1.2252 - categorical_accuracy: 0.4465 - val_loss: 1.5012 - val_categorical_accuracy: 0.3000\n",
      "Epoch 8/30\n",
      "159/159 [==============================] - 11441s 72s/step - loss: 1.2951 - categorical_accuracy: 0.4591 - val_loss: 1.5109 - val_categorical_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "159/159 [==============================] - 11452s 72s/step - loss: 1.1965 - categorical_accuracy: 0.5031 - val_loss: 1.4845 - val_categorical_accuracy: 0.3000\n",
      "Epoch 10/30\n",
      "159/159 [==============================] - 11349s 71s/step - loss: 1.2466 - categorical_accuracy: 0.4906 - val_loss: 1.4848 - val_categorical_accuracy: 0.3000\n",
      "Epoch 11/30\n",
      "159/159 [==============================] - 11564s 73s/step - loss: 1.2224 - categorical_accuracy: 0.4591 - val_loss: 1.5062 - val_categorical_accuracy: 0.3000\n",
      "Epoch 12/30\n",
      "159/159 [==============================] - 11467s 72s/step - loss: 1.2156 - categorical_accuracy: 0.4591 - val_loss: 1.5013 - val_categorical_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "159/159 [==============================] - 11468s 72s/step - loss: 1.2229 - categorical_accuracy: 0.5031 - val_loss: 1.5060 - val_categorical_accuracy: 0.3000\n",
      "Epoch 14/30\n",
      "159/159 [==============================] - 11293s 71s/step - loss: 1.2134 - categorical_accuracy: 0.4906 - val_loss: 1.4747 - val_categorical_accuracy: 0.4000\n",
      "Epoch 15/30\n",
      "159/159 [==============================] - 11505s 72s/step - loss: 1.2741 - categorical_accuracy: 0.4717 - val_loss: 1.4848 - val_categorical_accuracy: 0.3000\n",
      "Epoch 16/30\n",
      "159/159 [==============================] - 11600s 73s/step - loss: 1.2512 - categorical_accuracy: 0.4465 - val_loss: 1.4871 - val_categorical_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "159/159 [==============================] - 11451s 72s/step - loss: 1.2322 - categorical_accuracy: 0.4654 - val_loss: 1.4899 - val_categorical_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "159/159 [==============================] - 11382s 72s/step - loss: 1.2329 - categorical_accuracy: 0.5031 - val_loss: 1.4928 - val_categorical_accuracy: 0.4000\n",
      "Epoch 19/30\n",
      "159/159 [==============================] - 11379s 72s/step - loss: 1.2640 - categorical_accuracy: 0.4277 - val_loss: 1.4527 - val_categorical_accuracy: 0.3500\n",
      "Epoch 20/30\n",
      "159/159 [==============================] - 11440s 72s/step - loss: 1.2322 - categorical_accuracy: 0.4465 - val_loss: 1.4918 - val_categorical_accuracy: 0.3500\n",
      "Epoch 21/30\n",
      "158/159 [============================>.] - ETA: 1:05 - loss: 1.2062 - categorical_accuracy: 0.4557"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-adb7326ec375>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m history = model.fit_generator(v_generator,\n\u001b[0;32m----> 2\u001b[0;31m                               epochs=30, validation_data=validation_generator)\n\u001b[0m",
      "\u001b[0;32m/opt/python-3.6-packages/keras/2.2.4/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/python-3.6-packages/keras/2.2.4/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/python-3.6-packages/keras/2.2.4/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    232\u001b[0m                             \u001b[0mval_enqueuer_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m                             \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                             workers=0)\n\u001b[0m\u001b[1;32m    235\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                         \u001b[0;31m# No need for try/except because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/python-3.6-packages/keras/2.2.4/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/python-3.6-packages/keras/2.2.4/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate_generator\u001b[0;34m(self, generator, steps, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[1;32m   1470\u001b[0m             \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1471\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m             verbose=verbose)\n\u001b[0m\u001b[1;32m   1473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/python-3.6-packages/keras/2.2.4/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mevaluate_generator\u001b[0;34m(model, generator, steps, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m             \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m                 raise ValueError('Output of generator should be a tuple '\n",
      "\u001b[0;32m/opt/python-3.6-packages/keras/2.2.4/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    596\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/5.2.0/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/5.2.0/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/5.2.0/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/5.2.0/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(v_generator,\n",
    "                              epochs=30, validation_data=validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-280ddfeb645c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# list all data in history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# summarize history for accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'binary_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_binary_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['binary_accuracy'])\n",
    "plt.plot(history.history['val_binary_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "159/159 [==============================] - 12136s 76s/step - loss: 1.2338 - categorical_accuracy: 0.4340 - val_loss: 1.4873 - val_categorical_accuracy: 0.3000\n",
      "Epoch 2/30\n",
      "159/159 [==============================] - 11458s 72s/step - loss: 1.2354 - categorical_accuracy: 0.4654 - val_loss: 1.5100 - val_categorical_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "159/159 [==============================] - 11456s 72s/step - loss: 1.2151 - categorical_accuracy: 0.4465 - val_loss: 1.4727 - val_categorical_accuracy: 0.3500\n",
      "Epoch 4/30\n",
      "159/159 [==============================] - 11347s 71s/step - loss: 1.2195 - categorical_accuracy: 0.4717 - val_loss: 1.4730 - val_categorical_accuracy: 0.4000\n",
      "Epoch 5/30\n",
      "159/159 [==============================] - 11508s 72s/step - loss: 1.2185 - categorical_accuracy: 0.4340 - val_loss: 1.4684 - val_categorical_accuracy: 0.4000\n",
      "Epoch 6/30\n",
      "159/159 [==============================] - 11619s 73s/step - loss: 1.2399 - categorical_accuracy: 0.4717 - val_loss: 1.5050 - val_categorical_accuracy: 0.2000\n",
      "Epoch 7/30\n",
      "107/159 [===================>..........] - ETA: 56:07 - loss: 1.2430 - categorical_accuracy: 0.4673"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(v_generator,\n",
    "                              epochs=30, validation_data=validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
