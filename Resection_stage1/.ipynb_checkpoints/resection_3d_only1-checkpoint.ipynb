{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Traceback (most recent call last):\n  File \"/opt/python-3.6-packages/tensorflow-gpu/1.7.0rc0/tensorflow/python/pywrap_tensorflow.py\", line 58, in <module>\n    from tensorflow.python.pywrap_tensorflow_internal import *\n  File \"/opt/python-3.6-packages/tensorflow-gpu/1.7.0rc0/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\n    _pywrap_tensorflow_internal = swig_import_helper()\n  File \"/opt/python-3.6-packages/tensorflow-gpu/1.7.0rc0/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n  File \"/opt/anaconda3/5.2.0/lib/python3.6/imp.py\", line 243, in load_module\n    return load_dynamic(name, filename, file)\n  File \"/opt/anaconda3/5.2.0/lib/python3.6/imp.py\", line 343, in load_dynamic\n    return _load(spec)\nImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://www.tensorflow.org/install/install_sources#common_installation_problems\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/opt/python-3.6-packages/tensorflow-gpu/1.7.0rc0/tensorflow/python/pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m   \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpywrap_tensorflow_internal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m   \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpywrap_tensorflow_internal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/python-3.6-packages/tensorflow-gpu/1.7.0rc0/tensorflow/python/pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_mod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0m_pywrap_tensorflow_internal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mswig_import_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mswig_import_helper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/python-3.6-packages/tensorflow-gpu/1.7.0rc0/tensorflow/python/pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36mswig_import_helper\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                 \u001b[0m_mod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_pywrap_tensorflow_internal'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/5.2.0/lib/python3.6/imp.py\u001b[0m in \u001b[0;36mload_module\u001b[0;34m(name, file, filename, details)\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mload_dynamic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mtype_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mPKG_DIRECTORY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/5.2.0/lib/python3.6/imp.py\u001b[0m in \u001b[0;36mload_dynamic\u001b[0;34m(name, path, file)\u001b[0m\n\u001b[1;32m    342\u001b[0m             name=name, loader=loader, origin=path)\n\u001b[0;32m--> 343\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: libcublas.so.9.0: cannot open shared object file: No such file or directory",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-ee9093a4d9af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CUDA_VISIBLE_DEVICES\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"0\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mgpu_options\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGPUOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mallow_growth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msess_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConfigProto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpu_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgpu_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/python-3.6-packages/tensorflow-gpu/1.7.0rc0/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# pylint: disable=wildcard-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# pylint: disable=redefined-builtin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;31m# pylint: enable=wildcard-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/python-3.6-packages/tensorflow-gpu/1.7.0rc0/tensorflow/python/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;31m# Protocol buffers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/python-3.6-packages/tensorflow-gpu/1.7.0rc0/tensorflow/python/pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msome\u001b[0m \u001b[0mcommon\u001b[0m \u001b[0mreasons\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msolutions\u001b[0m\u001b[0;34m.\u001b[0m  \u001b[0mInclude\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mentire\u001b[0m \u001b[0mstack\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m above this error message when asking for help.\"\"\" % traceback.format_exc()\n\u001b[0;32m---> 74\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;31m# pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: Traceback (most recent call last):\n  File \"/opt/python-3.6-packages/tensorflow-gpu/1.7.0rc0/tensorflow/python/pywrap_tensorflow.py\", line 58, in <module>\n    from tensorflow.python.pywrap_tensorflow_internal import *\n  File \"/opt/python-3.6-packages/tensorflow-gpu/1.7.0rc0/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\n    _pywrap_tensorflow_internal = swig_import_helper()\n  File \"/opt/python-3.6-packages/tensorflow-gpu/1.7.0rc0/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n  File \"/opt/anaconda3/5.2.0/lib/python3.6/imp.py\", line 243, in load_module\n    return load_dynamic(name, filename, file)\n  File \"/opt/anaconda3/5.2.0/lib/python3.6/imp.py\", line 343, in load_dynamic\n    return _load(spec)\nImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://www.tensorflow.org/install/install_sources#common_installation_problems\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "gpu_options = tf.GPUOptions(allow_growth=True)\n",
    "sess_config = tf.ConfigProto(gpu_options=gpu_options)\n",
    "tf.keras.backend.set_session(tf.Session(config=sess_config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "#import tqdm\n",
    "import numpy as np\n",
    "#import pandas as pd\n",
    "import multiprocessing\n",
    "import pydicom as dicom\n",
    "import nibabel as nib\n",
    "#from keras import utils as kutils\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def load_image(label_fpath, transpose=False):\n",
    "    #encode_name = label_fpath[-39: -7]\n",
    "    label_data = nib.load(label_fpath)\n",
    "    label_array = label_data.get_fdata()\n",
    "    if transpose:\n",
    "        label_array = np.transpose(label_array, axes=(2, 1, 0))\n",
    "    return  label_array#, encode_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "info = pd.read_csv('/data2/pancreas/Nifti_data/data_list.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"/data2/pancreas/Nifti_data/image\"\n",
    "label_path = \"/data2/pancreas/Nifti_data/label\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "resec0_names = info.groupby(\"resection\").get_group(0).case_id.unique()\n",
    "resec1_names = info.groupby(\"resection\").get_group(1).case_id.unique()\n",
    "\n",
    "#combine resec0 and resec1 and shuffle\n",
    "resec = np.concatenate([resec0_names,resec1_names], axis = 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(resec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.zeros((len(resec), 1))\n",
    "for idx, name in enumerate(resec):\n",
    "    y[idx] = info[info.case_id == name].resection\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15,)\n",
      "(8,)\n"
     ]
    }
   ],
   "source": [
    "print(np.where(y[-30:] == 1)[0].shape)\n",
    "print(np.where(y[-50:-30] == 1)[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #check the num. of image in terms of z-axis\n",
    "# img_shape = []\n",
    "# for name in resec:\n",
    "#     img = load_image(os.path.join(image_path, \"IM_\"+name+\".nii.gz\"))\n",
    "    \n",
    "#     img_shape.append(img.shape[2])\n",
    "#     del img\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label_t = load_image(os.path.join(label_path, \"LB_\"+resec[0]+\".nii.gz\"))\n",
    "# np.max(np.where(label_t != 0)[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#determine the size of cube using label-img\n",
    "shape0 = np.zeros((len(resec), 2))\n",
    "shape1 = np.zeros((len(resec), 2))\n",
    "shape2 = np.zeros((len(resec), 2))\n",
    "for i, name in enumerate(resec) :\n",
    "    label = load_image(os.path.join(label_path, \"LB_\"+name+\".nii.gz\"))\n",
    "    shape0[i][0] = np.min(np.where(label != 0)[0])\n",
    "    shape0[i][1] = np.max(np.where(label != 0)[0])\n",
    "    shape1[i][0] = np.min(np.where(label != 0)[1])\n",
    "    shape1[i][1] = np.max(np.where(label != 0)[1])\n",
    "    shape2[i][0] = np.min(np.where(label != 0)[2])\n",
    "    shape2[i][1] = np.max(np.where(label != 0)[2])\n",
    "    del label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_t = load_image(os.path.join(label_path, \"LB_\"+resec[0]+\".nii.gz\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape0 = pd.read_csv(\"shape0.csv\")\n",
    "# shape1 = pd.read_csv(\"shape1.csv\")\n",
    "# shape2 = pd.read_csv(\"shape2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape = np.swapaxes(np.array([shape0[\"0\"], shape0[\"1\"], shape1[\"0\"], shape1[\"1\"], shape2[\"0\"], shape2[\"1\"]]), 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = np.concatenate([shape0, shape1, shape2], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save( \"shape.npz\", shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(182, 6)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load(\"shape.npz.npy\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"resec\", resec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"resec_y\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#New\n",
    "def extract_cube(r, img):#cube 360, 300, 110 ;; ranges = [xmin, xmax, ymin, ymax, zmin, zmax]\n",
    "    img_tmp = np.zeros((360, 300, 110))\n",
    "    img_tmp[:int(r[1]-r[0]), :int(r[3]-r[2]), :int(r[5]-r[4])] = img[int(r[0]):int(r[1]), int(r[2]):int(r[3]), int(r[4]):int(r[5])]\n",
    "    return img_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 72., 324., 145., 306.,   9.,  24.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test extract_cube\n",
    "label_t = extract_cube(shape[0, :], load_image(os.path.join(label_path, \"LB_\"+resec[0]+\".nii.gz\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(label_t[..., 1])\n",
    "plt.show()\n",
    "del label_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 72., 324., 145., 306.,   9.,  24.])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape[np.array(range(10))[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#y_idx => for construct (500, 1) vector\n",
    "map_df = pd.DataFrame(data={'resec_name': resec, 'shape': np.array(range(182)), 'target':y.reshape(182)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-25-79db5078fb45>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-25-79db5078fb45>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    module list\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Traceback (most recent call last):\n  File \"/opt/python-3.6-packages/tensorflow-gpu/1.7.0rc0/tensorflow/python/pywrap_tensorflow.py\", line 58, in <module>\n    from tensorflow.python.pywrap_tensorflow_internal import *\n  File \"/opt/python-3.6-packages/tensorflow-gpu/1.7.0rc0/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\n    _pywrap_tensorflow_internal = swig_import_helper()\n  File \"/opt/python-3.6-packages/tensorflow-gpu/1.7.0rc0/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n  File \"/opt/anaconda3/5.2.0/lib/python3.6/imp.py\", line 243, in load_module\n    return load_dynamic(name, filename, file)\n  File \"/opt/anaconda3/5.2.0/lib/python3.6/imp.py\", line 343, in load_dynamic\n    return _load(spec)\nImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://www.tensorflow.org/install/install_sources#common_installation_problems\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/opt/python-3.6-packages/tensorflow-gpu/1.7.0rc0/tensorflow/python/pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m   \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpywrap_tensorflow_internal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m   \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpywrap_tensorflow_internal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/python-3.6-packages/tensorflow-gpu/1.7.0rc0/tensorflow/python/pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_mod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0m_pywrap_tensorflow_internal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mswig_import_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mswig_import_helper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/python-3.6-packages/tensorflow-gpu/1.7.0rc0/tensorflow/python/pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36mswig_import_helper\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                 \u001b[0m_mod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_pywrap_tensorflow_internal'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/5.2.0/lib/python3.6/imp.py\u001b[0m in \u001b[0;36mload_module\u001b[0;34m(name, file, filename, details)\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mload_dynamic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mtype_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mPKG_DIRECTORY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/5.2.0/lib/python3.6/imp.py\u001b[0m in \u001b[0;36mload_dynamic\u001b[0;34m(name, path, file)\u001b[0m\n\u001b[1;32m    342\u001b[0m             name=name, loader=loader, origin=path)\n\u001b[0;32m--> 343\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: libcublas.so.9.0: cannot open shared object file: No such file or directory",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-0d8c22e1fae9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;31m#, load_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlayers\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mklayers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mkutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/python-3.6-packages/keras/2.2.4/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapplications\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/python-3.6-packages/keras/2.2.4/keras/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mio_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconv_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Globally-importable utils.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/python-3.6-packages/keras/2.2.4/keras/utils/conv_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoves\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/python-3.6-packages/keras/2.2.4/keras/backend/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;32melif\u001b[0m \u001b[0m_BACKEND\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tensorflow'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Using TensorFlow backend.\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtensorflow_backend\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;31m# Try and load external backend.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/python-3.6-packages/keras/2.2.4/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mops\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmoving_averages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/python-3.6-packages/tensorflow-gpu/1.7.0rc0/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# pylint: disable=wildcard-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# pylint: disable=redefined-builtin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;31m# pylint: enable=wildcard-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/python-3.6-packages/tensorflow-gpu/1.7.0rc0/tensorflow/python/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;31m# Protocol buffers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/python-3.6-packages/tensorflow-gpu/1.7.0rc0/tensorflow/python/pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msome\u001b[0m \u001b[0mcommon\u001b[0m \u001b[0mreasons\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msolutions\u001b[0m\u001b[0;34m.\u001b[0m  \u001b[0mInclude\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mentire\u001b[0m \u001b[0mstack\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m above this error message when asking for help.\"\"\" % traceback.format_exc()\n\u001b[0;32m---> 74\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;31m# pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: Traceback (most recent call last):\n  File \"/opt/python-3.6-packages/tensorflow-gpu/1.7.0rc0/tensorflow/python/pywrap_tensorflow.py\", line 58, in <module>\n    from tensorflow.python.pywrap_tensorflow_internal import *\n  File \"/opt/python-3.6-packages/tensorflow-gpu/1.7.0rc0/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\n    _pywrap_tensorflow_internal = swig_import_helper()\n  File \"/opt/python-3.6-packages/tensorflow-gpu/1.7.0rc0/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n  File \"/opt/anaconda3/5.2.0/lib/python3.6/imp.py\", line 243, in load_module\n    return load_dynamic(name, filename, file)\n  File \"/opt/anaconda3/5.2.0/lib/python3.6/imp.py\", line 343, in load_dynamic\n    return _load(spec)\nImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://www.tensorflow.org/install/install_sources#common_installation_problems\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help."
     ]
    }
   ],
   "source": [
    "from keras.models import Model#, load_model\n",
    "from keras import layers as klayers\n",
    "from keras.optimizers import Adam\n",
    "from keras import utils as kutils\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "\n",
    "from keras.layers import Conv3D, MaxPool3D, Flatten, Dense\n",
    "from keras.layers import Dropout, Input, BatchNormalization\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "#from plotly.offline import iplot, init_notebook_mode\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adadelta\n",
    "#import plotly.graph_objs as go\n",
    "from matplotlib.pyplot import cm\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "import keras\n",
    "import h5py\n",
    "\n",
    "#init_notebook_mode(connected=True)\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, multiply, concatenate,  MaxPool2D\n",
    "# from keras.layers import BatchNormalization, Activation, Embedding, ZeroPadding2D, Lambda\n",
    "from keras.layers.advanced_activations import LeakyReLU, ReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D, Conv1D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.utils import to_categorical\n",
    "import keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, LSTM, TimeDistributed, RepeatVector, Reshape\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "class resec_Generator1(kutils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, mapping_df, batch_size, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.mapping_df = mapping_df\n",
    "        self.data_num   = mapping_df.shape[0]\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(self.data_num / self.batch_size))\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        #print(\"enter0\")\n",
    "        batch_mapping_df = \\\n",
    "            self.mapping_df.iloc[index*self.batch_size: (index+1)*self.batch_size]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(batch_mapping_df)\n",
    "        return X, y\n",
    "\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        if self.shuffle:\n",
    "            self.mapping_df = self.mapping_df.sample(frac=1).reset_index(drop=True)\n",
    "            \n",
    "    def __data_generation(self, batch_mapping_df):\n",
    "        'Generates data containing batch_size samples' \n",
    "        # Initialization\n",
    "        X1 = np.zeros((  self.batch_size, 180, 300, 100, 1)) \n",
    "        X2 = np.zeros((  self.batch_size, 180, 300, 100, 1)) \n",
    "        y = np.zeros((self.batch_size))\n",
    "\n",
    "        # Generate data\n",
    "        cnt = 0\n",
    "        \n",
    "        for i, row in batch_mapping_df.iterrows():\n",
    "            img = extract_cube(shape[row['shape']], load_image(os.path.join(image_path, \"IM_\"+row['resec_name']+\".nii.gz\")))\n",
    "            X1[ cnt, :, :, :, 0] = img[:180, :, :100]\n",
    "            X2[ cnt, :, :, :, 0] = img[180:, :, :100]\n",
    "            #img = clip_img(load_image(os.path.join(image_path, \"IM_\"+row['resec_name']+\".nii.gz\")))\n",
    "            #print(\"resec_name =\", row['resec_name'])\n",
    "#             for j in range(40):\n",
    "#                 #print(\"img shape =\", img.shape)\n",
    "#                 #print(\"j =\", j)\n",
    "#                 X[j][cnt, :, :, :, 0] = extract_cube(img, j)\n",
    "            y[cnt] = row['target']\n",
    "\n",
    "#             position = extract_position(row['ref_idx'], row['point_idx'])\n",
    "#             tmp_cube = extract_cube(position, row['ref_idx'])\n",
    "#             if (tmp_cube.shape == (19, 19, 19)):\n",
    "#                 X[cnt, :, :, :, 0] = extract_cube(position, row['ref_idx'])\n",
    "#             else:\n",
    "#                 X[cnt, :, :, :, 0] = np.zeros((19, 19, 19))\n",
    "#             y_idx = row['y_idx']\n",
    "#             radius = ref[row['ref_idx']][row['point_idx'], 3]\n",
    "#             y1[cnt, y_idx] = 1\n",
    "#             y2[cnt, 0] = radius\n",
    "            cnt += 1\n",
    "        #print(X[5])\n",
    "        return [X1, X2], y\n",
    "\n",
    "# for name in resec:\n",
    "#     img = load_image(os.path.join(image_path, \"IM_\"+name+\".nii.gz\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(shape2).to_csv(\"shape2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_17 (InputLayer)           (None, 180, 300, 100 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_18 (InputLayer)           (None, 180, 300, 100 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_81 (Conv3D)              (None, 178, 298, 98, 896         input_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_86 (Conv3D)              (None, 178, 298, 98, 896         input_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 178, 298, 98, 128         conv3d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 178, 298, 98, 128         conv3d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_33 (Dropout)            (None, 178, 298, 98, 0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_35 (Dropout)            (None, 178, 298, 98, 0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_81 (MaxPooling3D) (None, 89, 149, 49,  0           dropout_33[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_86 (MaxPooling3D) (None, 89, 149, 49,  0           dropout_35[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_82 (Conv3D)              (None, 87, 147, 47,  13840       max_pooling3d_81[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_87 (Conv3D)              (None, 87, 147, 47,  13840       max_pooling3d_86[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 87, 147, 47,  64          conv3d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 87, 147, 47,  64          conv3d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_34 (Dropout)            (None, 87, 147, 47,  0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_36 (Dropout)            (None, 87, 147, 47,  0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_82 (MaxPooling3D) (None, 43, 73, 23, 1 0           dropout_34[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_87 (MaxPooling3D) (None, 43, 73, 23, 1 0           dropout_36[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_83 (Conv3D)              (None, 41, 71, 21, 1 6928        max_pooling3d_82[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_88 (Conv3D)              (None, 41, 71, 21, 1 6928        max_pooling3d_87[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 41, 71, 21, 1 64          conv3d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 41, 71, 21, 1 64          conv3d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_83 (MaxPooling3D) (None, 20, 35, 10, 1 0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_88 (MaxPooling3D) (None, 20, 35, 10, 1 0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_84 (Conv3D)              (None, 18, 33, 8, 16 6928        max_pooling3d_83[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_89 (Conv3D)              (None, 18, 33, 8, 16 6928        max_pooling3d_88[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 18, 33, 8, 16 64          conv3d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 18, 33, 8, 16 64          conv3d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_84 (MaxPooling3D) (None, 9, 16, 4, 16) 0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_89 (MaxPooling3D) (None, 9, 16, 4, 16) 0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_85 (Conv3D)              (None, 7, 14, 2, 16) 6928        max_pooling3d_84[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_90 (Conv3D)              (None, 7, 14, 2, 16) 6928        max_pooling3d_89[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 7, 14, 2, 16) 64          conv3d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 7, 14, 2, 16) 64          conv3d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_85 (MaxPooling3D) (None, 3, 7, 1, 16)  0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_90 (MaxPooling3D) (None, 3, 7, 1, 16)  0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 3, 7, 1, 32)  0           max_pooling3d_85[0][0]           \n",
      "                                                                 max_pooling3d_90[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_11 (Flatten)            (None, 672)          0           concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_31 (Dense)                (None, 800)          538400      flatten_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_32 (Dense)                (None, 100)          80100       dense_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_33 (Dense)                (None, 1)            101         dense_32[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 690,409\n",
      "Trainable params: 690,025\n",
      "Non-trainable params: 384\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import metrics\n",
    "tmp_x = Input((180, 300, 100, 1))\n",
    "x = Conv3D(filters=32, dilation_rate=1, kernel_size=(3, 3, 3), activation='relu')(tmp_x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = MaxPool3D()(x)\n",
    "\n",
    "x = Conv3D(filters=16, dilation_rate=1, kernel_size=(3, 3, 3), activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = MaxPool3D()(x)\n",
    "\n",
    "x = Conv3D(filters=16, dilation_rate=1, kernel_size=(3, 3, 3), activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPool3D()(x)\n",
    "\n",
    "x = Conv3D(filters=16, dilation_rate=1, kernel_size=(3, 3, 3), activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPool3D()(x)\n",
    "\n",
    "x = Conv3D(filters=16, dilation_rate=1, kernel_size=(3, 3, 3), activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPool3D()(x)\n",
    "\n",
    "\n",
    "tmp_y = Input((180, 300, 100, 1))\n",
    "y = Conv3D(filters=32, dilation_rate=1, kernel_size=(3, 3, 3), activation='relu')(tmp_y)\n",
    "y = BatchNormalization()(y)\n",
    "y = Dropout(0.5)(y)\n",
    "y = MaxPool3D()(y)\n",
    "\n",
    "y = Conv3D(filters=16, dilation_rate=1, kernel_size=(3, 3, 3), activation='relu')(y)\n",
    "y = BatchNormalization()(y)\n",
    "y = Dropout(0.5)(y)\n",
    "y = MaxPool3D()(y)\n",
    "\n",
    "y = Conv3D(filters=16, dilation_rate=1, kernel_size=(3, 3, 3), activation='relu')(y)\n",
    "y = BatchNormalization()(y)\n",
    "y = MaxPool3D()(y)\n",
    "\n",
    "y = Conv3D(filters=16, dilation_rate=1, kernel_size=(3, 3, 3), activation='relu')(y)\n",
    "y = BatchNormalization()(y)\n",
    "y = MaxPool3D()(y)\n",
    "\n",
    "y = Conv3D(filters=16, dilation_rate=1, kernel_size=(3, 3, 3), activation='relu')(y)\n",
    "y = BatchNormalization()(y)\n",
    "y = MaxPool3D()(y)\n",
    "\n",
    "x = concatenate([x, y], axis = 4)\n",
    "\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Dense(units=800, kernel_initializer='normal', activation='elu')(x)\n",
    "x = Dense(units=100, kernel_initializer='normal', activation='relu')(x)\n",
    "x = Dense(units=1, kernel_initializer='normal', activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=[tmp_x, tmp_y], outputs=x)\n",
    "adam_lr = 0.0002\n",
    "adam_beta_1 = 0.5\n",
    "model.compile(optimizer=Adam(lr=adam_lr, beta_1=adam_beta_1),\n",
    "              loss='binary_crossentropy', metrics = [metrics.binary_accuracy])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "v_generator = resec_Generator1(map_df[:-50], batch_size=batch_size)\n",
    "validation_generator = resec_Generator1(map_df[-50:-30], batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "132/132 [==============================] - 527s 4s/step - loss: 0.8971 - binary_accuracy: 0.4621 - val_loss: 0.6438 - val_binary_accuracy: 0.6000\n",
      "Epoch 2/4\n",
      "132/132 [==============================] - 503s 4s/step - loss: 0.6489 - binary_accuracy: 0.6667 - val_loss: 0.6822 - val_binary_accuracy: 0.6000\n",
      "Epoch 3/4\n",
      "132/132 [==============================] - 493s 4s/step - loss: 0.6041 - binary_accuracy: 0.6591 - val_loss: 0.8899 - val_binary_accuracy: 0.5000\n",
      "Epoch 4/4\n",
      "132/132 [==============================] - 499s 4s/step - loss: 0.5990 - binary_accuracy: 0.6667 - val_loss: 0.8156 - val_binary_accuracy: 0.5500\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(v_generator,\n",
    "                              epochs=4, validation_data=validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "132/132 [==============================] - 503s 4s/step - loss: 0.5286 - binary_accuracy: 0.7121 - val_loss: 0.8482 - val_binary_accuracy: 0.4500\n",
      "Epoch 2/10\n",
      " 15/132 [==>...........................] - ETA: 7:16 - loss: 0.4758 - binary_accuracy: 0.8000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-95-dc83e280791e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m history = model.fit_generator(v_generator,\n\u001b[0;32m----> 2\u001b[0;31m                               epochs=10, validation_data=validation_generator)\n\u001b[0m",
      "\u001b[0;32m/opt/python-3.6-packages/keras/2.2.4/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/python-3.6-packages/keras/2.2.4/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/python-3.6-packages/keras/2.2.4/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/python-3.6-packages/keras/2.2.4/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/python-3.6-packages/keras/2.2.4/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2719\u001b[0m                     \u001b[0;34m'In order to feed symbolic tensors to a Keras model '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2720\u001b[0m                     'in TensorFlow, you need tensorflow 1.8 or higher.')\n\u001b[0;32m-> 2721\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/python-3.6-packages/keras/2.2.4/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_legacy_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2691\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2692\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2693\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2694\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/python-3.6-packages/tensorflow-gpu/1.7.0rc0/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/python-3.6-packages/tensorflow-gpu/1.7.0rc0/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1140\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/python-3.6-packages/tensorflow-gpu/1.7.0rc0/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1321\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/python-3.6-packages/tensorflow-gpu/1.7.0rc0/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/python-3.6-packages/tensorflow-gpu/1.7.0rc0/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1310\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1312\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/python-3.6-packages/tensorflow-gpu/1.7.0rc0/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1418\u001b[0m         return tf_session.TF_Run(\n\u001b[1;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m             status, run_metadata)\n\u001b[0m\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1422\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(v_generator,\n",
    "                              epochs=10, validation_data=validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "356.0\n",
      "289.0\n",
      "105.0\n"
     ]
    }
   ],
   "source": [
    "# print(np.max(shape0[:, 1] - shape0[:, 0]))\n",
    "# print(np.max(shape1[:, 1] - shape1[:, 0]))\n",
    "# print(np.max(shape2[:, 1] - shape2[:, 0]))\n",
    "\n",
    "#cube shape : 360, 300, 110"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.0 452.0\n",
      "57.0 395.0\n",
      "2.0 605.0\n"
     ]
    }
   ],
   "source": [
    "# print(np.min(shape0[:, 0]), np.max(shape0[:, 1]))\n",
    "# print(np.min(shape1[:, 0]), np.max(shape1[:, 1]))\n",
    "# print(np.min(shape2[:, 0]), np.max(shape2[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f5e333b0390>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(shape2[:, 0], list(range(shape2.shape[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the center point for each image using label\n",
    "med0 = []\n",
    "med1 = []\n",
    "med2 = []\n",
    "for i, name in enumerate(resec) :\n",
    "    label = load_image(os.path.join(label_path, \"LB_\"+name+\".nii.gz\"))\n",
    "    med0.append(np.median(np.where(label != 0)[0]))\n",
    "    med1.append(np.median(np.where(label != 0)[1]))\n",
    "    med2.append(np.median(np.where(label != 0)[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "class resec_Generator(kutils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, mapping_df, batch_size, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.mapping_df = mapping_df\n",
    "        self.data_num   = mapping_df.shape[0]\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(self.data_num / self.batch_size))\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        #print(\"enter0\")\n",
    "        batch_mapping_df = \\\n",
    "            self.mapping_df.iloc[index*self.batch_size: (index+1)*self.batch_size]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(batch_mapping_df)\n",
    "        return X, y\n",
    "\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        if self.shuffle:\n",
    "            self.mapping_df = self.mapping_df.sample(frac=1).reset_index(drop=True)\n",
    "            \n",
    "    def __data_generation(self, batch_mapping_df):\n",
    "        'Generates data containing batch_size samples' \n",
    "        # Initialization\n",
    "        X = [np.zeros((self.batch_size, 60, 40, 100, 1)) for i in range(40)]\n",
    "        y = np.zeros((self.batch_size))\n",
    "\n",
    "        # Generate data\n",
    "        cnt = 0\n",
    "        \n",
    "        for i, row in batch_mapping_df.iterrows():\n",
    "            img = clip_img(load_image(os.path.join(image_path, \"IM_\"+row['resec_name']+\".nii.gz\")))\n",
    "            #print(\"resec_name =\", row['resec_name'])\n",
    "            for j in range(40):\n",
    "                #print(\"img shape =\", img.shape)\n",
    "                #print(\"j =\", j)\n",
    "                X[j][cnt, :, :, :, 0] = extract_cube(img, j)\n",
    "            y[cnt] = row['target']\n",
    "\n",
    "#             position = extract_position(row['ref_idx'], row['point_idx'])\n",
    "#             tmp_cube = extract_cube(position, row['ref_idx'])\n",
    "#             if (tmp_cube.shape == (19, 19, 19)):\n",
    "#                 X[cnt, :, :, :, 0] = extract_cube(position, row['ref_idx'])\n",
    "#             else:\n",
    "#                 X[cnt, :, :, :, 0] = np.zeros((19, 19, 19))\n",
    "#             y_idx = row['y_idx']\n",
    "#             radius = ref[row['ref_idx']][row['point_idx'], 3]\n",
    "#             y1[cnt, y_idx] = 1\n",
    "#             y2[cnt, 0] = radius\n",
    "            cnt += 1\n",
    "        #print(X[5])\n",
    "        return X, y\n",
    "\n",
    "# for name in resec:\n",
    "#     img = load_image(os.path.join(image_path, \"IM_\"+name+\".nii.gz\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_cube(center, img):#cube 360, 300, 110\n",
    "    \n",
    "    xyz = [360, 300, 110]\n",
    "    pad_zero = np.zeros((6, 1))\n",
    "    for i, thre in enumerate(xyz):\n",
    "        line1 = center[i] - int(thre/2)\n",
    "        line2 = center[i] + int(thre/2)\n",
    "        for j, line in enumerate([line1, line2]):\n",
    "            if (0<=line<=img.shape[i]):\n",
    "                continue\n",
    "            elif (line < 0):\n",
    "                pad_zero[i*2+j] = -line\n",
    "            elif (line > img.shape[i]):\n",
    "                pad_zero[i*2+j] = img.shape[i] - line \n",
    "    tmp_img = np.zeros((360, 300, 110))\n",
    "    for i, pad in enumerate(pad_zero):\n",
    "        axis = i%3\n",
    "        if axis == 0:\n",
    "            \n",
    "        if axis == 1:\n",
    "            \n",
    "        if axis == 2:\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#     shape_size = [360, 300, 110]\n",
    "#     tmp_img = np.zeros((360, 300, 110))\n",
    "#     for curr_axis in range(3):\n",
    "#         if img.shape[curr_axis] < shape_size[curr_axis]:\n",
    "                \n",
    "#         else:\n",
    "                \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers = np.swapaxes(np.array([med0, med1, med2]), 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#100:400 200:360 \n",
    "#60:5, 40:4, +-20 median   24 inouts \n",
    "def clip_img(img):# make image to be in shape of (300, 160, 200)\n",
    "    img = img[100:400, 200:360, :]\n",
    "    _med = int(img.shape[2]/2)\n",
    "    tmp_img = np.zeros((300, 160, 200))\n",
    "    if img.shape[2] < 200:\n",
    "        a = img.shape[2]\n",
    "        tmp_img[:, :, 100-_med : 100-_med+a] = img\n",
    "    else:\n",
    "        tmp_img = img[:, :, _med-100 : _med+100 ]\n",
    "    img = tmp_img\n",
    "    del tmp_img\n",
    "    return img\n",
    "    \n",
    "def extract_cube(img, i):#Input((60, 40, 30, 1)) ; the i-th cube\n",
    "    j = i%5\n",
    "    k = i%4\n",
    "    l = i%2\n",
    "    #print(img[j*60:(j+1)*60, k*40:(1+k)*40, l*30:(l+1)*30].shape)\n",
    "    return img[j*60:(j+1)*60, k*40:(1+k)*40, l*100:(l+1)*100]\n",
    "    \n",
    "    \n",
    "import pandas as pd\n",
    "#y_idx => for construct (500, 1) vector\n",
    "map_df = pd.DataFrame(data={'resec_name': resec, 'target':y.reshape(182)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "v_generator = resec_Generator(map_df[:-50], batch_size=batch_size)\n",
    "validation_generator = resec_Generator(map_df[-50:-30], batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[1,32,358,298,108] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: max_pooling3d_1/MaxPool3D = MaxPool3D[T=DT_FLOAT, data_format=\"NDHWC\", ksize=[1, 2, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 2, 1], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](dropout_1/cond/Merge)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: loss/mul/_421 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_3305_loss/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'max_pooling3d_1/MaxPool3D', defined at:\n  File \"/opt/anaconda3/5.2.0/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/opt/anaconda3/5.2.0/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/opt/anaconda3/5.2.0/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/opt/anaconda3/5.2.0/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/opt/anaconda3/5.2.0/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/opt/anaconda3/5.2.0/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/opt/anaconda3/5.2.0/lib/python3.6/asyncio/base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"/opt/anaconda3/5.2.0/lib/python3.6/asyncio/base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"/opt/anaconda3/5.2.0/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/opt/anaconda3/5.2.0/lib/python3.6/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/opt/anaconda3/5.2.0/lib/python3.6/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/opt/anaconda3/5.2.0/lib/python3.6/site-packages/tornado/gen.py\", line 787, in inner\n    self.run()\n  File \"/opt/anaconda3/5.2.0/lib/python3.6/site-packages/tornado/gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"/opt/anaconda3/5.2.0/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/opt/anaconda3/5.2.0/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/opt/anaconda3/5.2.0/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 272, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/opt/anaconda3/5.2.0/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/opt/anaconda3/5.2.0/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 542, in execute_request\n    user_expressions, allow_stdin,\n  File \"/opt/anaconda3/5.2.0/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/opt/anaconda3/5.2.0/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/opt/anaconda3/5.2.0/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/opt/anaconda3/5.2.0/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2854, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/opt/anaconda3/5.2.0/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2880, in _run_cell\n    return runner(coro)\n  File \"/opt/anaconda3/5.2.0/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/opt/anaconda3/5.2.0/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3057, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/opt/anaconda3/5.2.0/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3248, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/opt/anaconda3/5.2.0/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3325, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-48-2bc8f0fd4dc8>\", line 5, in <module>\n    x = MaxPool3D()(x)\n  File \"/opt/python-3.6-packages/keras/2.2.4/keras/engine/base_layer.py\", line 457, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/opt/python-3.6-packages/keras/2.2.4/keras/layers/pooling.py\", line 374, in call\n    data_format=self.data_format)\n  File \"/opt/python-3.6-packages/keras/2.2.4/keras/layers/pooling.py\", line 432, in _pooling_function\n    padding, data_format, pool_mode='max')\n  File \"/opt/python-3.6-packages/keras/2.2.4/keras/backend/tensorflow_backend.py\", line 4024, in pool3d\n    data_format=tf_data_format)\n  File \"/opt/python-3.6-packages/tensorflow-gpu/1.7.0rc0/tensorflow/python/ops/gen_nn_ops.py\", line 4693, in max_pool3d\n    padding=padding, data_format=data_format, name=name)\n  File \"/opt/python-3.6-packages/tensorflow-gpu/1.7.0rc0/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/opt/python-3.6-packages/tensorflow-gpu/1.7.0rc0/tensorflow/python/framework/ops.py\", line 3290, in create_op\n    op_def=op_def)\n  File \"/opt/python-3.6-packages/tensorflow-gpu/1.7.0rc0/tensorflow/python/framework/ops.py\", line 1654, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[1,32,358,298,108] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: max_pooling3d_1/MaxPool3D = MaxPool3D[T=DT_FLOAT, data_format=\"NDHWC\", ksize=[1, 2, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 2, 1], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](dropout_1/cond/Merge)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: loss/mul/_421 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_3305_loss/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/opt/python-3.6-packages/tensorflow-gpu/1.7.0rc0/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/python-3.6-packages/tensorflow-gpu/1.7.0rc0/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1312\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/python-3.6-packages/tensorflow-gpu/1.7.0rc0/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m             status, run_metadata)\n\u001b[0m\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/python-3.6-packages/tensorflow-gpu/1.7.0rc0/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    517\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[1,32,358,298,108] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: max_pooling3d_1/MaxPool3D = MaxPool3D[T=DT_FLOAT, data_format=\"NDHWC\", ksize=[1, 2, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 2, 1], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](dropout_1/cond/Merge)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: loss/mul/_421 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_3305_loss/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-38e8f9ac39f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m history = model.fit_generator(v_generator,\n\u001b[0;32m----> 2\u001b[0;31m                               epochs=4, validation_data=validation_generator)\n\u001b[0m",
      "\u001b[0;32m/opt/python-3.6-packages/keras/2.2.4/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/python-3.6-packages/keras/2.2.4/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/python-3.6-packages/keras/2.2.4/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/python-3.6-packages/keras/2.2.4/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/python-3.6-packages/keras/2.2.4/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2719\u001b[0m                     \u001b[0;34m'In order to feed symbolic tensors to a Keras model '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2720\u001b[0m                     'in TensorFlow, you need tensorflow 1.8 or higher.')\n\u001b[0;32m-> 2721\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/python-3.6-packages/keras/2.2.4/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_legacy_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2691\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2692\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2693\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2694\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/python-3.6-packages/tensorflow-gpu/1.7.0rc0/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/python-3.6-packages/tensorflow-gpu/1.7.0rc0/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1140\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/python-3.6-packages/tensorflow-gpu/1.7.0rc0/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1321\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/python-3.6-packages/tensorflow-gpu/1.7.0rc0/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[1,32,358,298,108] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: max_pooling3d_1/MaxPool3D = MaxPool3D[T=DT_FLOAT, data_format=\"NDHWC\", ksize=[1, 2, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 2, 1], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](dropout_1/cond/Merge)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: loss/mul/_421 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_3305_loss/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'max_pooling3d_1/MaxPool3D', defined at:\n  File \"/opt/anaconda3/5.2.0/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/opt/anaconda3/5.2.0/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/opt/anaconda3/5.2.0/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/opt/anaconda3/5.2.0/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/opt/anaconda3/5.2.0/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/opt/anaconda3/5.2.0/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/opt/anaconda3/5.2.0/lib/python3.6/asyncio/base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"/opt/anaconda3/5.2.0/lib/python3.6/asyncio/base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"/opt/anaconda3/5.2.0/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/opt/anaconda3/5.2.0/lib/python3.6/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/opt/anaconda3/5.2.0/lib/python3.6/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/opt/anaconda3/5.2.0/lib/python3.6/site-packages/tornado/gen.py\", line 787, in inner\n    self.run()\n  File \"/opt/anaconda3/5.2.0/lib/python3.6/site-packages/tornado/gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"/opt/anaconda3/5.2.0/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/opt/anaconda3/5.2.0/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/opt/anaconda3/5.2.0/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 272, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/opt/anaconda3/5.2.0/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/opt/anaconda3/5.2.0/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 542, in execute_request\n    user_expressions, allow_stdin,\n  File \"/opt/anaconda3/5.2.0/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/opt/anaconda3/5.2.0/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/opt/anaconda3/5.2.0/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/opt/anaconda3/5.2.0/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2854, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/opt/anaconda3/5.2.0/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2880, in _run_cell\n    return runner(coro)\n  File \"/opt/anaconda3/5.2.0/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/opt/anaconda3/5.2.0/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3057, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/opt/anaconda3/5.2.0/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3248, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/opt/anaconda3/5.2.0/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3325, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-48-2bc8f0fd4dc8>\", line 5, in <module>\n    x = MaxPool3D()(x)\n  File \"/opt/python-3.6-packages/keras/2.2.4/keras/engine/base_layer.py\", line 457, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/opt/python-3.6-packages/keras/2.2.4/keras/layers/pooling.py\", line 374, in call\n    data_format=self.data_format)\n  File \"/opt/python-3.6-packages/keras/2.2.4/keras/layers/pooling.py\", line 432, in _pooling_function\n    padding, data_format, pool_mode='max')\n  File \"/opt/python-3.6-packages/keras/2.2.4/keras/backend/tensorflow_backend.py\", line 4024, in pool3d\n    data_format=tf_data_format)\n  File \"/opt/python-3.6-packages/tensorflow-gpu/1.7.0rc0/tensorflow/python/ops/gen_nn_ops.py\", line 4693, in max_pool3d\n    padding=padding, data_format=data_format, name=name)\n  File \"/opt/python-3.6-packages/tensorflow-gpu/1.7.0rc0/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/opt/python-3.6-packages/tensorflow-gpu/1.7.0rc0/tensorflow/python/framework/ops.py\", line 3290, in create_op\n    op_def=op_def)\n  File \"/opt/python-3.6-packages/tensorflow-gpu/1.7.0rc0/tensorflow/python/framework/ops.py\", line 1654, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[1,32,358,298,108] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: max_pooling3d_1/MaxPool3D = MaxPool3D[T=DT_FLOAT, data_format=\"NDHWC\", ksize=[1, 2, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 2, 1], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](dropout_1/cond/Merge)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: loss/mul/_421 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_3305_loss/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(v_generator,\n",
    "                              epochs=4, validation_data=validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
