{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "#import tqdm\n",
    "import numpy as np\n",
    "#import pandas as pd\n",
    "import multiprocessing\n",
    "import pydicom as dicom\n",
    "import nibabel as nib\n",
    "#from keras import utils as kutils\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def load_label(label_fpath, transpose=False):\n",
    "    #encode_name = label_fpath[-39: -7]\n",
    "    label_data = nib.load(label_fpath)\n",
    "    label_array = label_data.get_fdata()\n",
    "    if transpose:\n",
    "        label_array = np.transpose(label_array, axes=(2, 1, 0))\n",
    "    return  label_array#, encode_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "info = pd.read_csv('/data2/pancreas/Nifti_data/data_list.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_of_patient : 367\n",
      "204\n",
      "164\n",
      "103\n",
      "82\n",
      "num_of_healthy_patient : 184\n",
      "num_of_tumor_patient : 183\n"
     ]
    }
   ],
   "source": [
    "id0_total = info.groupby(\"patient_id\").size()[0]\n",
    "num_of_patient = len(info.groupby(\"patient_id\").size()) + id0_total - 1\n",
    "print(\"num_of_patient :\", num_of_patient)\n",
    "print(len(info.groupby(\"patient_id\").size()))\n",
    "print(id0_total)\n",
    "\n",
    "id0_healthy = info[info.type == \"healthy\"].groupby(\"patient_id\").size()[0]\n",
    "num_of_healthy_patient = len(info[info.type == \"healthy\"].groupby(\"patient_id\").size()) + id0_healthy - 1\n",
    "print(len(info[info.type == \"healthy\"].groupby(\"patient_id\").size()))\n",
    "print(id0_healthy)\n",
    "print(\"num_of_healthy_patient :\", num_of_healthy_patient)\n",
    "print(\"num_of_tumor_patient :\", num_of_patient - num_of_healthy_patient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resection</th>\n",
       "      <th>200_list</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">0.0</th>\n",
       "      <th>test</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>validation</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">1.0</th>\n",
       "      <th>test</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>validation</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      total\n",
       "resection 200_list         \n",
       "0.0       test           14\n",
       "          train          44\n",
       "          validation     16\n",
       "1.0       test            6\n",
       "          train          16\n",
       "          validation      4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info['total'] = [1]*len(info)\n",
    "pd.DataFrame(info.groupby([\"resection\", \"200_list\"]).sum().total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resection</th>\n",
       "      <th>stage</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">0.0</th>\n",
       "      <th>I</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IIA</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IIB</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>III</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IV</th>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">1.0</th>\n",
       "      <th>IB</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>II</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IIA</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IIB</th>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>III</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IV</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 total\n",
       "resection stage       \n",
       "0.0       I          1\n",
       "          IIA        3\n",
       "          IIB        4\n",
       "          III       22\n",
       "          IV        65\n",
       "          X          1\n",
       "1.0       IB         4\n",
       "          II         1\n",
       "          IIA       19\n",
       "          IIB       44\n",
       "          III       10\n",
       "          IV         8"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import isnan\n",
    "pd.DataFrame(info.groupby([\"resection\", \"stage\"]).sum().total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_id1 = info.groupby(\"resection\").get_group(1).case_id\n",
    "case_id0 = info.groupby(\"resection\").get_group(0).case_id\n",
    "size1 = info.groupby(\"resection\").get_group(1).size\n",
    "size0 = info.groupby(\"resection\").get_group(0).size\n",
    "stage1 = info.groupby(\"resection\").get_group(1).stage\n",
    "stage0 = info.groupby(\"resection\").get_group(0).stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86\n",
      "96\n"
     ]
    }
   ],
   "source": [
    "print(len(case_id1))\n",
    "print(len(case_id0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, db='mnist', z_dim=128, cc_dim=1, dc_dim=10):\n",
    "        super(Generator, self).__init__()\n",
    "        self.db = db\n",
    "\n",
    "        if self.db == 'mnist':\n",
    "            self.fc = nn.Sequential(\n",
    "                nn.Linear(z_dim + cc_dim + dc_dim, 1024),\n",
    "                nn.BatchNorm2d(1024),\n",
    "                nn.ReLU(),\n",
    "\n",
    "                nn.Linear(1024, 128*7*7),\n",
    "                nn.BatchNorm2d(128*7*7),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "            self.conv = nn.Sequential(\n",
    "                # [-1, 128, 7, 7] -> [-1, 64, 14, 14]\n",
    "                nn.ConvTranspose2d(128,64,4,2,1),\n",
    "                nn.BatchNorm2d(64),\n",
    "                nn.ReLU(),\n",
    "\n",
    "                # -> [-1, 1, 28, 28]\n",
    "                nn.ConvTranspose2d(64,1,4,2,1),\n",
    "                nn.Tanh()\n",
    "            )\n",
    "        else:\n",
    "            self.main = nn.Sequential(\n",
    "                # [-1, z + cc + dc, 1, 1] -> [-1, 512, 4, 4]\n",
    "                nn.ConvTranspose2d(z_dim + cc_dim + dc_dim, 1024, 4, 1, 0),\n",
    "\n",
    "                nn.ConvTranspose2d(1024, 512, 4, 2, 1),\n",
    "                nn.BatchNorm2d(512),\n",
    "                nn.ReLU(),\n",
    "\n",
    "                # [-1, 256, 8, 8]\n",
    "                nn.ConvTranspose2d(512, 256, 4, 2, 1),\n",
    "                nn.BatchNorm2d(256),\n",
    "                nn.ReLU(),\n",
    "\n",
    "                # [-1, 128, 16, 16]\n",
    "                nn.ConvTranspose2d(256, 128, 4, 2, 1),\n",
    "                nn.BatchNorm2d(128),\n",
    "                nn.ReLU(),\n",
    "\n",
    "                # [-1, 3, 32, 32]\n",
    "                nn.ConvTranspose2d(128, 3, 4, 2, 1),\n",
    "                nn.Tanh()\n",
    "            )\n",
    "\n",
    "    def forward(self, z):\n",
    "        if self.db == 'mnist':\n",
    "            # [-1, z]\n",
    "            z = self.fc( z )\n",
    "\n",
    "            # [-1, 128*7*7] -> [-1, 128, 7, 7]\n",
    "            z = z.view(-1, 128, 7, 7)\n",
    "            out = self.conv(z)\n",
    "        else:\n",
    "            # [-1, z] -> [-1, z, 1, 1]\n",
    "            z = z.view(z.size(0), z.size(1), 1, 1)\n",
    "            out = self.main( z )\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, db='mnist', cc_dim = 1, dc_dim = 10):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.db = db\n",
    "        self.cc_dim = cc_dim\n",
    "        self.dc_dim = dc_dim\n",
    "\n",
    "        if self.db=='mnist':\n",
    "            self.conv = nn.Sequential(\n",
    "                # [-1, 1, 28, 28] -> [-1, 64, 14, 14]\n",
    "                nn.Conv2d(1, 64, 4, 2, 1),\n",
    "                nn.LeakyReLU(0.1, inplace=True),\n",
    "\n",
    "                # [-1, 128, 7, 7]\n",
    "                nn.Conv2d(64, 128, 4, 2, 1),\n",
    "                nn.BatchNorm2d(128),\n",
    "                nn.LeakyReLU(0.1, inplace=True),\n",
    "            )\n",
    "            self.fc = nn.Sequential(\n",
    "                nn.Linear(128*7*7, 128),\n",
    "                nn.BatchNorm2d(128),\n",
    "                nn.LeakyReLU(0.1, inplace=True),\n",
    "                nn.Linear(128, 1 + cc_dim + dc_dim)\n",
    "            )\n",
    "        else:\n",
    "            self.main = nn.Sequential(\n",
    "                # [-1, 3, 32, 32] -> [-1, 128, 16, 16]\n",
    "                nn.Conv2d(3, 128, 4, 2, 1),\n",
    "                nn.LeakyReLU(0.1, inplace=True),\n",
    "\n",
    "                # [-1, 256, 8, 8]\n",
    "                nn.Conv2d(128, 256, 4, 2, 1),\n",
    "                nn.BatchNorm2d(256),\n",
    "                nn.LeakyReLU(0.1, inplace=True),\n",
    "\n",
    "                # [-1, 512, 4, 4]\n",
    "                nn.Conv2d(256, 512, 4, 2, 1),\n",
    "                nn.BatchNorm2d(512),\n",
    "                nn.LeakyReLU(0.1, inplace=True),\n",
    "\n",
    "                nn.Conv2d(512, 1024, 4, 2, 1),\n",
    "                nn.BatchNorm2d(1024),\n",
    "                nn.LeakyReLU(0.1, inplace=True),\n",
    "\n",
    "                # [-1, 1 + cc_dim + dc_dim, 1, 1]\n",
    "                nn.Conv2d(1024, 1 + cc_dim + dc_dim, 4, 1, 0)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.db == 'mnist':\n",
    "            # -> [-1, 128*7*7]\n",
    "            tmp = self.conv(x).view(-1, 128*7*7)\n",
    "\n",
    "            # -> [-1, 1 + cc_dim + dc_dim]\n",
    "            out = self.fc(tmp)\n",
    "        else:\n",
    "            # -> [-1, 1 + cc_dim + dc_dim]\n",
    "            out = self.main(x).squeeze()\n",
    "\n",
    "        # Discrimination Output\n",
    "        out[:, 0] = F.sigmoid(out[:, 0].clone())\n",
    "\n",
    "        # Continuous Code Output = Value Itself\n",
    "        # Discrete Code Output (Class -> Softmax)\n",
    "        out[:, self.cc_dim + 1:self.cc_dim + 1 + self.dc_dim] = F.softmax(out[:, self.cc_dim + 1:self.cc_dim + 1 + self.dc_dim].clone())\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Conv2d(nn.Conv2d):\n",
    "    def reset_parameters(self):\n",
    "        stdv = np.sqrt(6 / ((self.in_channels  + self.out_channels) * np.prod(self.kernel_size)))\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.zero_()\n",
    "\n",
    "class ConvTranspose2d(nn.ConvTranspose2d):\n",
    "    def reset_parameters(self):\n",
    "        stdv = np.sqrt(6 / ((self.in_channels  + self.out_channels) * np.prod(self.kernel_size)))\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.zero_()\n",
    "\n",
    "class Linear(nn.Linear):\n",
    "    def reset_parameters(self):\n",
    "        stdv = np.sqrt(6 / (self.in_features + self.out_features))\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "\n",
    "\n",
    "import pylab as plt\n",
    "\n",
    "class InfoGAN:\n",
    "    def __init__(self, gen, dis, embedding_len, z_len, c1_len, c2_len, c3_len):\n",
    "        assert c1_len is not None and c1_len > 1, 'Must have a categorical code'\n",
    "\n",
    "        self.gen = gen.cuda()\n",
    "        self.dis = dis.cuda()\n",
    "\n",
    "        self.embedding_len = embedding_len\n",
    "        self.z_len = z_len\n",
    "        self.c1_len = c1_len\n",
    "        self.c2_len = c2_len\n",
    "        self.c3_len = c3_len\n",
    "\n",
    "        self.Q_cat = Linear(embedding_len, c1_len).cuda()\n",
    "        self.qcat_optim = optim.Adam(self.Q_cat.parameters(), lr = 2e-4)\n",
    "        if c2_len:\n",
    "            self.Q_con = Linear(embedding_len, c2_len).cuda()\n",
    "            self.qcon_optim = optim.Adam(self.Q_con.parameters(), lr = 2e-4)\n",
    "        if c3_len:\n",
    "            self.Q_bin = Linear(embedding_len, c3_len).cuda()\n",
    "            self.qbin_optim = optim.Adam(self.Q_bin.parameters(), lr = 2e-4)\n",
    "\n",
    "        self.g_optim = optim.Adam(self.gen.parameters(), lr = 1e-3)\n",
    "        self.d_optim = optim.Adam(self.dis.parameters(), lr = 2e-4)\n",
    "\n",
    "\n",
    "    def train_all(self, train_loader):\n",
    "        nll = nn.NLLLoss().cuda()\n",
    "        mse = nn.MSELoss().cuda()\n",
    "        bce = nn.BCELoss().cuda()\n",
    "\n",
    "        plt.figure(0, figsize = (32, 32))\n",
    "        for epoch in range(100):\n",
    "            pb = tqdm_notebook(total = train_loader.dataset.data_tensor.size()[0])\n",
    "            pb.set_description('Epoch ' + str(epoch + 1))\n",
    "            for i, (data, targets) in enumerate(train_loader):\n",
    "                ones = Variable(torch.ones(data.size()[0], 1)).cuda()\n",
    "                zeros = Variable(torch.zeros(data.size()[0], 1)).cuda()\n",
    "\n",
    "                z_dict = self.get_z(data.size()[0])\n",
    "                z = torch.cat([z_dict[k] for k in z_dict.keys()], dim = 1)\n",
    "\n",
    "                data = Variable(data.float().cuda(async = True)) / 255\n",
    "                targets = Variable(targets.float().cuda(async = True))\n",
    "\n",
    "                # Forward pass on real MNIST\n",
    "                out_dis, hid = self.dis(data)\n",
    "                c1 = F.log_softmax(self.Q_cat(hid))\n",
    "                loss_dis = mse(out_dis, ones) - torch.sum(targets * c1) / (torch.sum(targets) + 1e-3) # Loss for real MNIST\n",
    "\n",
    "                # Forward pass on generated MNIST\n",
    "                out_gen = self.gen(z)\n",
    "                out_dis, hid = self.dis(out_gen)\n",
    "\n",
    "                # Loss for generated MNIST\n",
    "                loss_dis = loss_dis + mse(out_dis, zeros)\n",
    "                loss_dis = loss_dis \n",
    "\n",
    "                # Zero gradient buffers for gen and Q_cat and backward pass\n",
    "                self.dis.zero_grad()\n",
    "                self.Q_cat.zero_grad()\n",
    "                loss_dis.backward(retain_graph = True) # We need PyTorch to retain the graph buffers so we can run backward again later\n",
    "                self.d_optim.step() # Apply the discriminator's update now since we have to delete its gradients later\n",
    "\n",
    "                # And backward pass and loss for generator and update\n",
    "                self.gen.zero_grad()\n",
    "                loss_gen = mse(out_dis, ones)\n",
    "                loss_gen.backward(retain_graph = True)\n",
    "                self.dis.zero_grad() # Don't want the gradients of the generator's objective in the discriminator\n",
    "\n",
    "                # Forward pass and loss for latent codes\n",
    "                loss_q = 0\n",
    "\n",
    "                c1 = F.log_softmax(self.Q_cat(hid))\n",
    "                loss_q += nll(c1, torch.max(z_dict['cat'], dim = 1)[1])\n",
    "\n",
    "                if self.c2_len:\n",
    "                    c2 = self.Q_con(hid)\n",
    "                    loss_q += 0.5 * mse(c2, z_dict['con']) # Multiply by 0.5 as we treat targets as Gaussian (and there's a coefficient of 0.5 when we take logs)\n",
    "                    self.Q_con.zero_grad() # Zero gradient buffers before the backward pass\n",
    "                if self.c3_len:\n",
    "                    c3 = F.sigmoid(self.Q_bin(hid))\n",
    "                    loss_q += bce(c3, z_dict['bin'])\n",
    "                    self.Q_bin.zero_grad() # Zero gradient buffers before the backward pass\n",
    "\n",
    "                # Backward pass for latent code objective\n",
    "                loss_q.backward()\n",
    "\n",
    "                # Do the updates for everything\n",
    "                self.d_optim.step()\n",
    "                self.g_optim.step()\n",
    "                self.qcat_optim.step()\n",
    "\n",
    "                if self.c2_len:\n",
    "                    self.qcon_optim.step()\n",
    "                if self.c3_len:\n",
    "                    self.qbin_optim.step()\n",
    "\n",
    "\n",
    "\n",
    "                pb.update(data.size()[0])\n",
    "                pb.set_postfix(loss_dis = loss_dis.cpu().data.numpy()[0], loss_gen = loss_gen.cpu().data.numpy()[0], loss_q = loss_q.cpu().data.numpy()[0])\n",
    "\n",
    "            pb.close()\n",
    "            plt.subplot(10, 10, epoch + 1)\n",
    "            plt.imshow(np.squeeze(np.transpose(out_gen.cpu().data.numpy()[0], (1, 2, 0))))\n",
    "\n",
    "\n",
    "    # Generate a noise vector and random latent codes for generator\n",
    "    def get_z(self, length, sequential = False):\n",
    "        weights = torch.Tensor([0.1] * 10)\n",
    "\n",
    "        z = {}\n",
    "        if self.z_len:\n",
    "            z['z'] = Variable(torch.randn(length, self.z_len)).cuda()\n",
    "\n",
    "        if self.c1_len:\n",
    "            if sequential:\n",
    "                cat_noise = Variable(torch.arange(0, self.c1_len).repeat(length // self.c1_len).long()).cuda()\n",
    "            else:\n",
    "                cat_noise = Variable(torch.multinomial(weights, num_samples = length, replacement = True)).cuda().view(-1)\n",
    "            onehot_noise = Variable(torch.zeros(length, self.c1_len)).cuda()\n",
    "            onehot_noise.data.scatter_(1, cat_noise.data.view(-1, 1), 1)\n",
    "            z['cat'] = onehot_noise\n",
    "\n",
    "        if self.c2_len:\n",
    "            #z['con'] = Variable(torch.randn(length, c2_len)).cuda()\n",
    "            z['con'] = Variable(torch.rand(length, self.c2_len)).cuda() * 2 - 1\n",
    "\n",
    "        if self.c3_len:\n",
    "            z['bin'] = Variable(torch.bernoulli(0.5 * torch.ones(length, self.c3_len))).cuda().float()\n",
    "\n",
    "        return z\n",
    "\n",
    "\n",
    "    def run_dis(self, x):\n",
    "        out = []\n",
    "        out_dis, hid = self.dis(x)\n",
    "        out += [out_dis]\n",
    "        if self.c1_len:\n",
    "            out += [F.softmax(self.Q_cat(hid))]\n",
    "        if self.c2_len:\n",
    "            out += [self.Q_con(hid)]\n",
    "        if self.c3_len:\n",
    "            out += [F.sigmoid(self.Q_bin(hid))]\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "    def save(self, directory):\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "\n",
    "        torch.save(self.gen.state_dict(), directory + 'gen.torch')\n",
    "        torch.save(self.dis.state_dict(), directory + 'dis.torch')\n",
    "        if self.c1_len:\n",
    "            torch.save(self.Q_cat.state_dict(), directory + 'qcat.torch')\n",
    "        if self.c2_len:\n",
    "            torch.save(self.Q_con.state_dict(), directory + 'qcon.torch')\n",
    "        if self.c3_len:\n",
    "            torch.save(self.Q_bin.state_dict(), directory + 'qbin.torch')\n",
    "\n",
    "\n",
    "    def load(self, directory):\n",
    "        self.gen.load_state_dict(torch.load(directory + 'gen.torch'))\n",
    "        self.dis.load_state_dict(torch.load(directory + 'dis.torch'))\n",
    "        if self.c1_len:\n",
    "            self.Q_cat.load_state_dict(torch.load(directory + 'qcat.torch'))\n",
    "        if self.c2_len:\n",
    "            self.Q_con.load_state_dict(torch.load(directory + 'qcon.torch'))\n",
    "        if self.c3_len:\n",
    "            self.Q_bin.load_state_dict(torch.load(directory + 'qbin.torch'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchvision\n",
      "  Using cached https://files.pythonhosted.org/packages/2e/45/0f2f3062c92d9cf1d5d7eabd3cae88cea9affbd2b17fb1c043627838cb0a/torchvision-0.3.0-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Requirement already satisfied: pillow>=4.1.1 in /opt/anaconda3/5.2.0/lib/python3.6/site-packages (from torchvision) (5.4.1)\n",
      "Requirement already satisfied: numpy in ./.local/lib/python3.6/site-packages (from torchvision) (1.15.0)\n",
      "Collecting torch>=1.1.0 (from torchvision)\n",
      "  Using cached https://files.pythonhosted.org/packages/69/60/f685fb2cfb3088736bafbc9bdbb455327bdc8906b606da9c9a81bae1c81e/torch-1.1.0-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Requirement already satisfied: six in /opt/anaconda3/5.2.0/lib/python3.6/site-packages (from torchvision) (1.12.0)\n",
      "Installing collected packages: torch, torchvision\n",
      "Successfully installed torch-1.1.0 torchvision-0.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "/home/u/wartytw/.local/lib/python3.6/site-packages/torchvision/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZN3c1019UndefinedTensorImpl10_singletonE",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-6dd351122000>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torchvision/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torchvision/models/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mshufflenetv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msegmentation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdetection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torchvision/models/detection/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfaster_rcnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmask_rcnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mkeypoint_rcnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torchvision/models/detection/faster_rcnn.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmisc\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmisc_nn_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMultiScaleRoIAlign\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torchvision/ops/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mboxes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox_iou\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mroi_align\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mroi_align\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRoIAlign\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mroi_pool\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mroi_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRoIPool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpoolers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMultiScaleRoIAlign\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfeature_pyramid_network\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFeaturePyramidNetwork\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torchvision/ops/boxes.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_C\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mnms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miou_threshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: /home/u/wartytw/.local/lib/python3.6/site-packages/torchvision/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZN3c1019UndefinedTensorImpl10_singletonE"
     ]
    }
   ],
   "source": [
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
